---
title: "[AI] 국내 의과대학 세포 분류 프로그램"
excerpt: "세포의 성장단계 분류 프로젝트"

toc: true
toc_sticky: true
categories:
  - Project
---

## About
세포의 성장단계는 총 3가지로 정의되어 있습니다.
변화의 폭이 크지않아 전문가의 눈으로만 확인이 가능해 분류 과정도 번거로울 뿐만 아니라 작업  인력풀도 좁았습니다.  
  
CNN model을 이용한 세포 분류 프로그램으로 전문가 수준의 분류 능력과 사람보다 빠른 속도로 구별해 낼 수 있게 하였습니다.  
  
  


## How to
### 1. Data Preprocessing
gray scale의 원본이미지를 512x512 pixel 단위로 이동하며 가장 픽셀 값의 합이 가장 낮은 지점(=세포 이미지)을 찾아내 불필요한 배경이미지를 제거  
**crop**된 이미지에 **Threshold, Histogram Normalization** 적용
  

```python
IMG_SIZE = 512

min_box = src_img[:IMG_SIZE, :IMG_SIZE]
interval = 10
cnt_rows = int((src_img.shape[0] - IMG_SIZE) / interval)
cnt_cols = int((src_img.shape[1] - IMG_SIZE) / interval)
for row in range(cnt_rows):
    for col in range(cnt_cols):
        cur_box = src_img[
                  row * interval: row * interval + IMG_SIZE,
                  col * interval: col * interval + IMG_SIZE
                  ]
        if np.sum(cur_box) < np.sum(min_box):
            min_box = cur_box
ret, min_box = cv2.threshold(min_box, 150, 255, cv2.THRESH_TRUNC)
HE_img = (min_box - np.min(min_box)) / (np.max(min_box) - np.min(min_box)) * 255
```

  
  
* 원본 이미지  
  
![](https://rib-president.github.io/assets/images/origin_cell.JPG){:.align-center}
  
* crop 이미지  
  
![](https://rib-president.github.io/assets/images/crop_cell.JPG){:.align-center}
  
_그외 **Augmentation(moving, random noise, rotation, flip)** 적용_
  

```python
img = skimage.util.random_noise(img, mode='gaussian', var=0.001)
```
```python
def augment_images(img, move_range=128, rotate_range=180, scale_range=0.1):
    dst_img = copy.deepcopy(img)
    # -------------------------------------------------------
    # Flip
    dst_img = cv2.flip(dst_img, random.randint(0, 1))
    #
    # -------------------------------------------------------
    # Moving: 128 pixel random
    rows, cols = dst_img.shape[:2]
    move_x = random.randint(-move_range, move_range)
    move_y = random.randint(-move_range, move_range)
    M = np.float32([[1, 0, move_x], [0, 1, move_y]])    # Transform Matrix
    dst_img = cv2.warpAffine(dst_img, M, (cols, rows))
    #
    # -------------------------------------------------------
    # Rotation: -180~180 degree random / Scale: x0.9 ~ x1.1 random
    rotate_val = random.randint(-rotate_range, rotate_range)
    scale = (1 - scale_range) + random.random() * 2 * scale_range
    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotate_val, scale)
    dst_img = cv2.warpAffine(dst_img, M, (cols, rows))
    #
    return dst_img
```
  
  
    
### 2. Modeling
* Conv Layer(x4, x5)
  * base network(2D Conv + ReLU, Max-pooling, Batch Normalization, Dropout)  
  * concat([base network, kernel_2x, kernel_4x, fast forward])
  
```python
for n in range(self.CONV_LAYERS):
    FILTER = FILTER * (n % 2 + 1)
    net_cell = tf.layers.conv2d(inputs=net_cell, filters=FILTER, kernel_size=KERNEL, padding='same', activation=tf.nn.relu)
    # --------------------------------------------------------------------------------
    ker_2x = tf.layers.conv2d(inputs=ker_2x, filters=FILTER, kernel_size=KERNEL * 2, padding='same', activation=tf.nn.relu)
    ker_2x = tf.layers.max_pooling2d(inputs=ker_2x, pool_size=POOL, strides=STRIDE, padding='same')
    ker_4x = tf.layers.conv2d(inputs=ker_4x, filters=FILTER, kernel_size=KERNEL * 4, padding='same', activation=tf.nn.relu)
    ker_4x = tf.layers.max_pooling2d(inputs=ker_4x, pool_size=POOL, strides=STRIDE, padding='same')
    # --------------------------------------------------------------------------------
    net_cell = tf.layers.max_pooling2d(inputs=net_cell, pool_size=POOL, strides=STRIDE, padding='same')
    net_cell = tf.layers.batch_normalization(inputs=net_cell, center=True, scale=True, training=self.IS_TRAIN)
    net_cell = tf.layers.dropout(inputs=net_cell, rate=DROP_OUT, training=self.IS_TRAIN)
    ffwd = tf.layers.max_pooling2d(inputs=ffwd, pool_size=POOL, strides=STRIDE, padding='same')
    net_cell = tf.concat([net_cell, ker_2x, ker_4x, ffwd], axis=3)
```
  


* FCN Layer(x2)
  * 보다 나은 정확도를 위해 day 정보 사용(세포 성장 기간과 성장 단계에 개연성 있음)  
  * features + one hot day infomation
  
```python
self.net_flat = tf.reshape(net_cell, [-1, net_cell.shape[1]._value * net_cell.shape[2]._value * net_cell.shape[3]._value])

for i in range(self.DENSE_LAYERS):
    self.net_flat = tf.layers.dense(self.net_flat, self.DENSE_NODE, activation=tf.nn.relu)
    if i == 0:
        self.net_flat = tf.concat([self.net_flat, self.D], axis=1) # self.D == day infomation
    self.net_flat = tf.layers.dropout(self.net_flat, DROP_OUT)
    self.DENSE_NODE = self.DENSE_NODE * 2
```
    

* classification, visualization
  * class 1, 2, 3  
  * Class Activation Map을 이용한 feature 확인(붉을 수록 모델이 봤을 때 특징이 있는 지점)

    

```python
def get_class_map(label, net_cam, im_width, weight):
    output_channels = int(net_cam.get_shape()[-1])   # channel num
    w_transpose = tf.transpose(weight)
    w_label = tf.gather(w_transpose, label)
    w_label = tf.reshape(w_label, [-1, output_channels, 1])
    net_cam_resized = tf.image.resize_bilinear(net_cam, [im_width, im_width])
    net_cam_resized_reshape = tf.reshape(net_cam_resized, [-1, im_width * im_width, output_channels])
    classmap = tf.matmul(net_cam_resized_reshape, w_label)
    classmap = tf.reshape(classmap, [-1, im_width, im_width])
    return classmap
```

  
![](https://rib-president.github.io/assets/images/cam_cell.JPG){:.align-center}
#### <center>CAM 이미지</center>

  
### 3. Inference
* Ensemble 적용
  * 2 classes, 3 classes(Conv Layer x4, x5) models inference
  * merge results -> 다양하게 학습된 여러 모델의 결과 합산으로 정확도 향상

  
## Architecture  
  
|Stages|Preprocessing|Modeling|
|:----:|:-----------:|:------:|
|Libraries|OpenCV, skimage|Tensorflow|
Language|Python|Python|
  
  
## Result
![](https://rib-president.github.io/assets/images/L1_P1_2_day0_E07_00000.png){:.align-center}  
#### <center>original Label: 1, Predict result: 1</center>
![](https://rib-president.github.io/assets/images/L3_P3_2_day5_A12_00000.png){:.align-center}  
#### <center>original Label: 3, Predict result: 3</center>  
  
  
  

